{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "You are an expert exam question setter for competitive exams, corporate assessments, and technical certifications.\n",
    "\n",
    "Task:\n",
    "Generate {total_number_of_questions} multiple-choice questions (MCQs) for the given topics and difficulty levels.\n",
    "\n",
    "Topics and Difficulty Levels:\n",
    "{topics_and_difficulty}\n",
    "\n",
    "Rules:\n",
    "1. Distribute questions proportionally among topics and difficulty levels.\n",
    "2. For each topic:\n",
    "   - If multiple difficulty levels are given (e.g., Easy and Medium), include a mix of those difficulties.\n",
    "3. Difficulty calibration:\n",
    "   - Easy: Simple recall or definition-based.\n",
    "   - Medium: Application-based, requires some reasoning.\n",
    "   - Hard: Scenario or case-study based, requires deep understanding.\n",
    "4. Each MCQ must have:\n",
    "   - 1 question\n",
    "   - 4 answer options: A, B, C, D\n",
    "   - Exactly one correct answer\n",
    "   - Plausible distractors for wrong answers\n",
    "   - A one-line explanation after the answer\n",
    "5. Do not repeat questions or answers.\n",
    "6. Use clear, concise, unambiguous language.\n",
    "\n",
    "Output Format:\n",
    "Q<number>. <Question text>  \n",
    "Topic: <Topic Name>  \n",
    "Difficulty: <Easy/Medium/Hard>  \n",
    "A. <Option A>  \n",
    "B. <Option B>  \n",
    "C. <Option C>  \n",
    "D. <Option D>  \n",
    "Answer: <Correct Option Letter>  \n",
    "Explanation: <One-line explanation>  \n",
    "\n",
    "Now, generate the questions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key = KEY, model_name=\"gpt-3.5-turbo\", temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"total_number_of_questions\", \"topics_and_difficulty\"],\n",
    "    template=PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain=LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "   You are an expert question-setter for competitive exams and corporate skill assessments.\n",
      "\n",
      "   Task:\n",
      "   Generate 5 multiple-choice questions (MCQs) for the topic: Python Programming.\n",
      "   The difficulty level should be: Intermediate.\n",
      "   Follow the exact output format.\n",
      "\n",
      "   Rules:\n",
      "   1. Questions must be factually correct and relevant to the topic.\n",
      "   2. Provide 4 answer options: A, B, C, and D.\n",
      "   3. Only ONE option should be correct.\n",
      "   4. Distractors (wrong options) should be plausible but clearly incorrect.\n",
      "   5. After each question, state:\n",
      "      - Correct answer (e.g., \"Answer: B\")\n",
      "      - One-line explanation of the correct answer.\n",
      "   6. Do not repeat questions or answers.\n",
      "   7. Use clear, concise language.\n",
      "\n",
      "   Output Format:\n",
      "   Q1. <Question text> \n",
      "   Topic : <Topic Name> \n",
      "   Difficulty Level : <Easy/Medium/Hard>\n",
      "   A. <Option A>  \n",
      "   B. <Option B>  \n",
      "   C. <Option C>  \n",
      "   D. <Option D>  \n",
      "   Answer: <Correct Option Letter>  \n",
      "   Explanation: <One-line explanation>  \n",
      "\n",
      "   Q2. <Question text>  \n",
      "   ...\n",
      "\n",
      "   Example:\n",
      "   Q1. Which protocol is used for secure communication over the Internet? \n",
      "   Topic : Internet Security \n",
      "   Difficulty Level : Medium\n",
      "   A. HTTP  \n",
      "   B. HTTPS  \n",
      "   C. FTP  \n",
      "   D. SMTP  \n",
      "   Answer: B  \n",
      "   Explanation: HTTPS encrypts data between the client and server using SSL/TLS.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = quiz_chain.run({\"number_of_questions\": 5, \"topic\": \"Python Programming\", \"difficulty_level\": \"Intermediate\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1. What does the built-in Python function 'len()' do? \n",
      "   Topic: Python Programming\n",
      "   Difficulty Level: Intermediate\n",
      "   A. Returns the total memory consumed by an object\n",
      "   B. Returns the length of a sequence such as a string or list\n",
      "   C. Returns the position of a substring within a string\n",
      "   D. Returns the ASCII value of a character\n",
      "   Answer: B\n",
      "   Explanation: The 'len()' function returns the number of items in a sequence or collection.\n",
      "\n",
      "Q2. What will be the output of the following code snippet in Python?\n",
      "\n",
      "    nums = [1, 2, 3, 4]\n",
      "    squares = list(map(lambda x: x**2, nums))\n",
      "    print(squares)\n",
      "    \n",
      "   Topic: Python Programming\n",
      "   Difficulty Level: Intermediate\n",
      "   A. [1, 4, 9, 16]\n",
      "   B. [2, 4, 6, 8]\n",
      "   C. [1, 3, 5, 7]\n",
      "   D. [0, 1, 2, 3]\n",
      "   Answer: A\n",
      "   Explanation: The code snippet uses a lambda function with map to calculate square of each number in the list.\n",
      "\n",
      "Q3. In Python, what is the purpose of the 'continue' statement in a loop?\n",
      "   Topic: Python Programming\n",
      "   Difficulty Level: Intermediate\n",
      "   A. Terminates the loop completely\n",
      "   B. Skips the remaining code in the loop and continues with the next iteration\n",
      "   C. Halts execution of the loop without exiting the program\n",
      "   D. Jumps to a specific line in the loop\n",
      "   Answer: B\n",
      "   Explanation: The 'continue' statement skips the remaining code in the loop and goes to the next iteration.\n",
      "\n",
      "Q4. Which of the following data structures in Python is mutable?\n",
      "   Topic: Python Programming\n",
      "   Difficulty Level: Intermediate\n",
      "   A. Tuple\n",
      "   B. List\n",
      "   C. String\n",
      "   D. Dictionary\n",
      "   Answer: B\n",
      "   Explanation: Lists in Python are mutable, meaning their elements can be changed after the list is created.\n",
      "\n",
      "Q5. What is the output of the following code snippet in Python?\n",
      "\n",
      "    def test_func(a=1, b=2):\n",
      "        return a + b\n",
      "    \n",
      "    print(test_func(b=3))\n",
      "    \n",
      "   Topic: Python Programming\n",
      "   Difficulty Level: Intermediate\n",
      "   A. 1\n",
      "   B. 2\n",
      "   C. 3\n",
      "   D. 4\n",
      "   Answer: C\n",
      "   Explanation: The function 'test_func' is called with the argument 'b=3', so it returns the sum of 1 and 3 which is 4.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_list = [\n",
    "    {\"topic\": \"Cloud Computing\", \"difficulty\": \"Easy, Medium\"},\n",
    "    {\"topic\": \"English Grammar\", \"difficulty\": \"Easy\"},\n",
    "    {\"topic\": \"Most recent updates about Artificial Intelligence\", \"difficulty\": \"Medium, Hard\"},\n",
    "    {\"topic\": \"Aptitude (Percentages)\", \"difficulty\": \"Easy, Medium\"}\n",
    "]\n",
    "\n",
    "topics_str = \"\\n\".join([f\"{t['topic']} – {t['difficulty']}\" for t in topics_list])\n",
    "\n",
    "formatted_prompt = quiz_generation_prompt.format(\n",
    "    total_number_of_questions=12,\n",
    "    topics_and_difficulty=topics_str\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain = LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert exam question setter for competitive exams, corporate assessments, and technical certifications.\n",
      "\n",
      "Task:\n",
      "Generate 10 multiple-choice questions (MCQs) for the given topics and difficulty levels.\n",
      "\n",
      "Topics and Difficulty Levels:\n",
      "Cloud Computing – Easy, Medium\n",
      "English Grammar – Easy\n",
      "Most recent updates about Artificial Intelligence – Medium, Hard\n",
      "Aptitude (Percentages) – Easy, Medium\n",
      "\n",
      "Rules:\n",
      "1. Distribute questions proportionally among topics and difficulty levels.\n",
      "2. For each topic:\n",
      "   - If multiple difficulty levels are given (e.g., Easy and Medium), include a mix of those difficulties.\n",
      "3. Difficulty calibration:\n",
      "   - Easy: Simple recall or definition-based.\n",
      "   - Medium: Application-based, requires some reasoning.\n",
      "   - Hard: Scenario or case-study based, requires deep understanding.\n",
      "4. Each MCQ must have:\n",
      "   - 1 question\n",
      "   - 4 answer options: A, B, C, D\n",
      "   - Exactly one correct answer\n",
      "   - Plausible distractors for wrong answers\n",
      "   - A one-line explanation after the answer\n",
      "5. Do not repeat questions or answers.\n",
      "6. Use clear, concise, unambiguous language.\n",
      "\n",
      "Output Format:\n",
      "Q<number>. <Question text>  \n",
      "Topic: <Topic Name>  \n",
      "Difficulty: <Easy/Medium/Hard>  \n",
      "A. <Option A>  \n",
      "B. <Option B>  \n",
      "C. <Option C>  \n",
      "D. <Option D>  \n",
      "Answer: <Correct Option Letter>  \n",
      "Explanation: <One-line explanation>  \n",
      "\n",
      "Now, generate the questions.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response_2 = quiz_chain.invoke({\"total_number_of_questions\" : 10, \"topics_and_difficulty\": topics_str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_number_of_questions: 10\n",
      "topics_and_difficulty: Cloud Computing – Easy, Medium\n",
      "English Grammar – Easy\n",
      "Most recent updates about Artificial Intelligence – Medium, Hard\n",
      "Aptitude (Percentages) – Easy, Medium\n",
      "quiz: 1. What is the main advantage of cloud computing?  \n",
      "Topic: Cloud Computing  \n",
      "Difficulty: Easy  \n",
      "A. Cost-effectiveness  \n",
      "B. Higher security risks  \n",
      "C. Limited scalability  \n",
      "D. Slower processing speed  \n",
      "Answer: A  \n",
      "Explanation: Cloud computing offers cost-effectiveness due to its pay-as-you-go model.\n",
      "\n",
      "2. Which of the following sentences contains a grammar mistake?  \n",
      "Topic: English Grammar  \n",
      "Difficulty: Easy  \n",
      "A. She goes to the gym every day.  \n",
      "B. He don't like ice cream.  \n",
      "C. They were running in the park.  \n",
      "D. I have finished my homework.  \n",
      "Answer: B  \n",
      "Explanation: The correct form is \"He doesn't like ice cream.\"\n",
      "\n",
      "3. What is a recent advancement in Artificial Intelligence related to natural language processing?  \n",
      "Topic: Artificial Intelligence  \n",
      "Difficulty: Medium  \n",
      "A. Reinforcement learning  \n",
      "B. Neural machine translation  \n",
      "C. Image recognition  \n",
      "D. Support vector machines  \n",
      "Answer: B  \n",
      "Explanation: Neural machine translation has seen significant progress in recent AI advancements.\n",
      "\n",
      "4. If a shirt originally costs $40 and is discounted by 25%, what is the final price of the shirt?  \n",
      "Topic: Aptitude (Percentages)  \n",
      "Difficulty: Easy  \n",
      "A. $15  \n",
      "B. $30  \n",
      "C. $35  \n",
      "D. $45  \n",
      "Answer: C  \n",
      "Explanation: Applying a 25% discount reduces the original price by $10.\n",
      "\n",
      "5. Which cloud service model provides the highest level of control and customization for users?  \n",
      "Topic: Cloud Computing  \n",
      "Difficulty: Medium  \n",
      "A. Software as a Service (SaaS)  \n",
      "B. Platform as a Service (PaaS)  \n",
      "C. Infrastructure as a Service (IaaS)  \n",
      "D. Function as a Service (FaaS)  \n",
      "Answer: C  \n",
      "Explanation: Infrastructure as a Service (IaaS) allows users to have more control over the underlying infrastructure.\n",
      "\n",
      "6. Choose the correct sentence in terms of subject-verb agreement.  \n",
      "Topic: English Grammar  \n",
      "Difficulty: Easy  \n",
      "A. The team is playing well.  \n",
      "B. The team are playing well.  \n",
      "C. The team am playing well.  \n",
      "D. The team were playing well.  \n",
      "Answer: A  \n",
      "Explanation: Subject \"team\" takes a singular verb \"is.\"\n",
      "\n",
      "7. Which recent AI application uses Generative Adversarial Networks (GANs) for creating realistic images?  \n",
      "Topic: Artificial Intelligence  \n",
      "Difficulty: Hard  \n",
      "A. Autonomous vehicles  \n",
      "B. Healthcare diagnosis  \n",
      "C. Deepfakes  \n",
      "D. Automated customer service  \n",
      "Answer: C  \n",
      "Explanation: GANs are commonly used in creating deepfake images.\n",
      "\n",
      "8. What is 75% of 80?  \n",
      "Topic: Aptitude (Percentages)  \n",
      "Difficulty: Medium  \n",
      "A. 60  \n",
      "B. 65  \n",
      "C. 70  \n",
      "D. 75  \n",
      "Answer: A  \n",
      "Explanation: Calculate 75% of 80 as 0.75 * 80 = 60.\n",
      "\n",
      "9. Which cloud deployment model involves a single organization using a cloud exclusively?  \n",
      "Topic: Cloud Computing  \n",
      "Difficulty: Easy  \n",
      "A. Public cloud  \n",
      "B. Private cloud  \n",
      "C. Hybrid cloud  \n",
      "D. Community cloud  \n",
      "Answer: B  \n",
      "Explanation: Private cloud is used exclusively by a single organization.\n",
      "\n",
      "10. Identify the incorrect use of \"its\" or \"it's\" in the following sentence.  \n",
      "Topic: English Grammar  \n",
      "Difficulty: Medium  \n",
      "A. The dog wagged it's tail happily.  \n",
      "B. Its too hot outside to go for a walk.  \n",
      "C. The team celebrated its victory.  \n",
      "D. It's important to follow the rules.  \n",
      "Answer: A  \n",
      "Explanation: The correct form is \"The dog wagged its tail happily.\"\n"
     ]
    }
   ],
   "source": [
    "for k, v in (response_2).items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('total_number_of_questions', 10), ('topics_and_difficulty', 'Cloud Computing – Easy, Medium\\nEnglish Grammar – Easy\\nArtificial Intelligence – Medium, Hard\\nAptitude (Percentages) – Easy, Medium'), ('quiz', '1. Which of the following is a popular cloud computing service provided by Amazon Web Services (AWS)?  \\nTopic: Cloud Computing  \\nDifficulty: Easy  \\nA. Google Cloud  \\nB. Microsoft Azure  \\nC. AWS Lambda  \\nD. IBM Cloud  \\nAnswer: C  \\nExplanation: AWS Lambda is a serverless compute service offered by Amazon Web Services.\\n\\n2. Identify the correct sentence in terms of English grammar.  \\nTopic: English Grammar  \\nDifficulty: Easy  \\nA. She is going to the market yesterday.  \\nB. He will finished his work soon.  \\nC. They have eaten dinner already.  \\nD. I didn\\'t went to the party last night.  \\nAnswer: C  \\nExplanation: The sentence \"They have eaten dinner already\" uses the correct tense and word order.\\n\\n3. Which of the following is an example of Weak AI (Narrow AI) technology?  \\nTopic: Artificial Intelligence  \\nDifficulty: Medium  \\nA. Virtual Personal Assistants like Siri or Alexa  \\nB. Self-driving cars  \\nC. IBM\\'s Watson  \\nD. General Artificial Intelligence (AGI)  \\nAnswer: A  \\nExplanation: Virtual Personal Assistants like Siri or Alexa are examples of Narrow AI that is designed for specific tasks.\\n\\n4. If the price of a product is increased by 20%, by what percentage should it be reduced to bring it back to its original price?  \\nTopic: Aptitude (Percentages)  \\nDifficulty: Easy  \\nA. 10%  \\nB. 15%  \\nC. 16.67%  \\nD. 20%  \\nAnswer: C  \\nExplanation: The product needs to be reduced by 16.67% to return to its original price after a 20% increase.\\n\\n5. Which cloud computing deployment model provides resources to multiple organizations, but with restrictions for customization or security measures?  \\nTopic: Cloud Computing  \\nDifficulty: Medium  \\nA. Private Cloud  \\nB. Public Cloud  \\nC. Hybrid Cloud  \\nD. Community Cloud  \\nAnswer: D  \\nExplanation: Community Cloud is a deployment model where resources are shared among organizations with specific restrictions.\\n\\n6. Choose the correct form of the verb to complete the sentence: \"She ____ to the concert last night.\"  \\nTopic: English Grammar  \\nDifficulty: Easy  \\nA. Go  \\nB. Gone  \\nC. Goes  \\nD. Went  \\nAnswer: D  \\nExplanation: The past tense form \"went\" completes the sentence correctly.\\n\\n7. What is the primary goal of Artificial General Intelligence (AGI)?  \\nTopic: Artificial Intelligence  \\nDifficulty: Hard  \\nA. Mimic human intelligence in all domains  \\nB. Perform specialized tasks with superior accuracy  \\nC. Improve machine learning algorithms  \\nD. Expand the capabilities of Weak AI systems  \\nAnswer: A  \\nExplanation: AGI aims to replicate human intelligence across various tasks and domains.\\n\\n8. If a student scores 80 marks out of 100, what percentage did the student score?  \\nTopic: Aptitude (Percentages)  \\nDifficulty: Easy  \\nA. 80%  \\nB. 85%  \\nC. 90%  \\nD. 75%  \\nAnswer: A  \\nExplanation: The student scored 80%, calculated as (80/100) * 100.\\n\\n9. Which cloud computing service model offers software applications over the internet that are managed by a third-party provider?  \\nTopic: Cloud Computing  \\nDifficulty: Easy  \\nA. Infrastructure as a Service (IaaS)  \\nB. Platform as a Service (PaaS)  \\nC. Software as a Service (SaaS)  \\nD. Function as a Service (FaaS)  \\nAnswer: C  \\nExplanation: Software as a Service (SaaS) provides applications over the internet without the need for installation or maintenance.\\n\\n10. The concept of \"machine learning\" falls under which category of Artificial Intelligence?  \\nTopic: Artificial Intelligence  \\nDifficulty: Medium  \\nA. Natural Language Processing (NLP)  \\nB. Robotics  \\nC. Computer Vision  \\nD. Learning and Adaptive Systems  \\nAnswer: D  \\nExplanation: Machine learning is classified under Learning and Adaptive Systems in the field of Artificial Intelligence.')])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(response_2).items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Which of the following is a popular cloud computing service provided by Amazon Web Services (AWS)?  \n",
      "Topic: Cloud Computing  \n",
      "Difficulty: Easy  \n",
      "A. Google Cloud  \n",
      "B. Microsoft Azure  \n",
      "C. AWS Lambda  \n",
      "D. IBM Cloud  \n",
      "Answer: C  \n",
      "Explanation: AWS Lambda is a serverless compute service offered by Amazon Web Services.\n",
      "\n",
      "2. Identify the correct sentence in terms of English grammar.  \n",
      "Topic: English Grammar  \n",
      "Difficulty: Easy  \n",
      "A. She is going to the market yesterday.  \n",
      "B. He will finished his work soon.  \n",
      "C. They have eaten dinner already.  \n",
      "D. I didn't went to the party last night.  \n",
      "Answer: C  \n",
      "Explanation: The sentence \"They have eaten dinner already\" uses the correct tense and word order.\n",
      "\n",
      "3. Which of the following is an example of Weak AI (Narrow AI) technology?  \n",
      "Topic: Artificial Intelligence  \n",
      "Difficulty: Medium  \n",
      "A. Virtual Personal Assistants like Siri or Alexa  \n",
      "B. Self-driving cars  \n",
      "C. IBM's Watson  \n",
      "D. General Artificial Intelligence (AGI)  \n",
      "Answer: A  \n",
      "Explanation: Virtual Personal Assistants like Siri or Alexa are examples of Narrow AI that is designed for specific tasks.\n",
      "\n",
      "4. If the price of a product is increased by 20%, by what percentage should it be reduced to bring it back to its original price?  \n",
      "Topic: Aptitude (Percentages)  \n",
      "Difficulty: Easy  \n",
      "A. 10%  \n",
      "B. 15%  \n",
      "C. 16.67%  \n",
      "D. 20%  \n",
      "Answer: C  \n",
      "Explanation: The product needs to be reduced by 16.67% to return to its original price after a 20% increase.\n",
      "\n",
      "5. Which cloud computing deployment model provides resources to multiple organizations, but with restrictions for customization or security measures?  \n",
      "Topic: Cloud Computing  \n",
      "Difficulty: Medium  \n",
      "A. Private Cloud  \n",
      "B. Public Cloud  \n",
      "C. Hybrid Cloud  \n",
      "D. Community Cloud  \n",
      "Answer: D  \n",
      "Explanation: Community Cloud is a deployment model where resources are shared among organizations with specific restrictions.\n",
      "\n",
      "6. Choose the correct form of the verb to complete the sentence: \"She ____ to the concert last night.\"  \n",
      "Topic: English Grammar  \n",
      "Difficulty: Easy  \n",
      "A. Go  \n",
      "B. Gone  \n",
      "C. Goes  \n",
      "D. Went  \n",
      "Answer: D  \n",
      "Explanation: The past tense form \"went\" completes the sentence correctly.\n",
      "\n",
      "7. What is the primary goal of Artificial General Intelligence (AGI)?  \n",
      "Topic: Artificial Intelligence  \n",
      "Difficulty: Hard  \n",
      "A. Mimic human intelligence in all domains  \n",
      "B. Perform specialized tasks with superior accuracy  \n",
      "C. Improve machine learning algorithms  \n",
      "D. Expand the capabilities of Weak AI systems  \n",
      "Answer: A  \n",
      "Explanation: AGI aims to replicate human intelligence across various tasks and domains.\n",
      "\n",
      "8. If a student scores 80 marks out of 100, what percentage did the student score?  \n",
      "Topic: Aptitude (Percentages)  \n",
      "Difficulty: Easy  \n",
      "A. 80%  \n",
      "B. 85%  \n",
      "C. 90%  \n",
      "D. 75%  \n",
      "Answer: A  \n",
      "Explanation: The student scored 80%, calculated as (80/100) * 100.\n",
      "\n",
      "9. Which cloud computing service model offers software applications over the internet that are managed by a third-party provider?  \n",
      "Topic: Cloud Computing  \n",
      "Difficulty: Easy  \n",
      "A. Infrastructure as a Service (IaaS)  \n",
      "B. Platform as a Service (PaaS)  \n",
      "C. Software as a Service (SaaS)  \n",
      "D. Function as a Service (FaaS)  \n",
      "Answer: C  \n",
      "Explanation: Software as a Service (SaaS) provides applications over the internet without the need for installation or maintenance.\n",
      "\n",
      "10. The concept of \"machine learning\" falls under which category of Artificial Intelligence?  \n",
      "Topic: Artificial Intelligence  \n",
      "Difficulty: Medium  \n",
      "A. Natural Language Processing (NLP)  \n",
      "B. Robotics  \n",
      "C. Computer Vision  \n",
      "D. Learning and Adaptive Systems  \n",
      "Answer: D  \n",
      "Explanation: Machine learning is classified under Learning and Adaptive Systems in the field of Artificial Intelligence.\n"
     ]
    }
   ],
   "source": [
    "print(response_2[\"quiz\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With recent trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "PROMPT = \"\"\"\n",
    "You are an expert exam question setter for competitive exams, corporate assessments, and technical certifications.\n",
    "\n",
    "You are given the following context from external sources:\n",
    "{context}\n",
    "\n",
    "Task:\n",
    "Generate {total_number_of_questions} multiple-choice questions (MCQs) for the given topics and difficulty levels.\n",
    "\n",
    "Topics and Difficulty Levels:\n",
    "{topics_and_difficulty}\n",
    "\n",
    "Rules:\n",
    "1. Use the provided context ONLY for recent trends topics. \n",
    "2. If a topic does not require recent info, use your own knowledge.\n",
    "3. Distribute questions proportionally among topics and difficulty levels.\n",
    "4. For each topic:\n",
    "   - If multiple difficulty levels are given (e.g., Easy and Medium), include a mix of those difficulties.\n",
    "5. Difficulty calibration:\n",
    "   - Easy: Simple recall or definition-based.\n",
    "   - Medium: Application-based, requires some reasoning.\n",
    "   - Hard: Scenario or case-study based, requires deep understanding.\n",
    "6. Each MCQ must have:\n",
    "   - 1 question\n",
    "   - 4 answer options: A, B, C, D\n",
    "   - Exactly one correct answer\n",
    "   - Plausible distractors for wrong answers\n",
    "   - A one-line explanation after the answer\n",
    "7. Do not repeat questions or answers.\n",
    "8. Use clear, concise, unambiguous language.\n",
    "\n",
    "Output Format:\n",
    "Q<number>. <Question text>  \n",
    "Topic: <Topic Name>  \n",
    "Difficulty: <Easy/Medium/Hard>  \n",
    "A. <Option A>  \n",
    "B. <Option B>  \n",
    "C. <Option C>  \n",
    "D. <Option D>  \n",
    "Answer: <Correct Option Letter>  \n",
    "Explanation: <One-line explanation>  \n",
    "\n",
    "Now, generate the questions.\n",
    "\"\"\"\n",
    "\n",
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"total_number_of_questions\", \"topics_and_difficulty\", \"context\"],\n",
    "    template=PROMPT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokulsundeep/Desktop/Learnings/mcqgen/env/lib/python3.8/site-packages/langchain_community/utilities/duckduckgo_search.py:62: UserWarning: backend='api' is deprecated, using backend='auto'\n",
      "  ddgs_gen = ddgs.text(\n"
     ]
    },
    {
     "ename": "DuckDuckGoSearchException",
     "evalue": "https://html.duckduckgo.com/html 202 Ratelimit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDuckDuckGoSearchException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m topics_list:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecent\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 22\u001b[0m         search_results \u001b[38;5;241m=\u001b[39m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtopic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m         context_parts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTopic: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSearch Results:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msearch_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m context_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(context_parts) \u001b[38;5;28;01mif\u001b[39;00m context_parts \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo external context required.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Learnings/mcqgen/env/lib/python3.8/site-packages/langchain_core/tools/base.py:586\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[1;32m    585\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(error_to_raise)\n\u001b[0;32m--> 586\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[1;32m    587\u001b[0m output \u001b[38;5;241m=\u001b[39m _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, status)\n\u001b[1;32m    588\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(output, color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Learnings/mcqgen/env/lib/python3.8/site-packages/langchain_core/tools/base.py:555\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run):\n\u001b[1;32m    554\u001b[0m     tool_kwargs[config_param] \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m--> 555\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_and_artifact\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/Learnings/mcqgen/env/lib/python3.8/site-packages/langchain_community/tools/ddg_search/tool.py:73\u001b[0m, in \u001b[0;36mDuckDuckGoSearchRun._run\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run\u001b[39m(\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     69\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     70\u001b[0m     run_manager: Optional[CallbackManagerForToolRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     71\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     72\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Use the tool.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Learnings/mcqgen/env/lib/python3.8/site-packages/langchain_community/utilities/duckduckgo_search.py:95\u001b[0m, in \u001b[0;36mDuckDuckGoSearchAPIWrapper.run\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run query through DuckDuckGo and return concatenated results.\"\"\"\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ddgs_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnews\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     97\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ddgs_news(query)\n",
      "File \u001b[0;32m~/Desktop/Learnings/mcqgen/env/lib/python3.8/site-packages/langchain_community/utilities/duckduckgo_search.py:62\u001b[0m, in \u001b[0;36mDuckDuckGoSearchAPIWrapper._ddgs_text\u001b[0;34m(self, query, max_results)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mduckduckgo_search\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DDGS\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m DDGS() \u001b[38;5;28;01mas\u001b[39;00m ddgs:\n\u001b[0;32m---> 62\u001b[0m     ddgs_gen \u001b[38;5;241m=\u001b[39m \u001b[43mddgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafesearch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafesearch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimelimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_results\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ddgs_gen:\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [r \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m ddgs_gen]\n",
      "File \u001b[0;32m~/Desktop/Learnings/mcqgen/env/lib/python3.8/site-packages/duckduckgo_search/duckduckgo_search.py:253\u001b[0m, in \u001b[0;36mDDGS.text\u001b[0;34m(self, keywords, region, safesearch, timelimit, backend, max_results)\u001b[0m\n\u001b[1;32m    250\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError to search using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m backend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    251\u001b[0m         err \u001b[38;5;241m=\u001b[39m ex\n\u001b[0;32m--> 253\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m DuckDuckGoSearchException(err)\n",
      "\u001b[0;31mDuckDuckGoSearchException\u001b[0m: https://html.duckduckgo.com/html 202 Ratelimit"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Web Search Tool\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "topics_list = [\n",
    "    {\"topic\": \"AI Agents\", \"difficulty\": \"Medium, Hard\", \"recent\": True},\n",
    "    {\"topic\": \"English Grammar\", \"difficulty\": \"Easy\", \"recent\": False}\n",
    "]\n",
    "\n",
    "# Build topics string\n",
    "topics_str = \"\\n\".join([f\"{t['topic']} - {t['difficulty']}\" for t in topics_list])\n",
    "\n",
    "# Collect context\n",
    "context_parts = []\n",
    "for t in topics_list:\n",
    "    if t.get(\"recent\"):\n",
    "        search_results = search.run(t[\"topic\"])\n",
    "        context_parts.append(f\"Topic: {t['topic']}\\nSearch Results:\\n{search_results}\")\n",
    "context_str = \"\\n\\n\".join(context_parts) if context_parts else \"No external context required.\"\n",
    "\n",
    "# Format final prompt\n",
    "final_prompt = quiz_generation_prompt.format(\n",
    "    total_number_of_questions=8,\n",
    "    topics_and_difficulty=topics_str,\n",
    "    context=context_str\n",
    ")\n",
    "\n",
    "# Run LLM\n",
    "response = llm.invoke(final_prompt)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting duckduckgo-search\n",
      "  Downloading duckduckgo_search-7.2.1-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: click>=8.1.7 in /Users/gokulsundeep/Desktop/Learnings/mcqgen/env/lib/python3.8/site-packages (from duckduckgo-search) (8.1.8)\n",
      "Collecting primp>=0.10.0 (from duckduckgo-search)\n",
      "  Downloading primp-0.15.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting lxml>=5.3.0 (from duckduckgo-search)\n",
      "  Downloading lxml-6.0.0.tar.gz (4.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hDownloading duckduckgo_search-7.2.1-py3-none-any.whl (19 kB)\n",
      "Downloading primp-0.15.0-cp38-abi3-macosx_11_0_arm64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: lxml\n",
      "  Building wheel for lxml (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lxml: filename=lxml-6.0.0-cp38-cp38-macosx_11_0_arm64.whl size=1728263 sha256=a686f7e2d047ea7b1c22184577907b9cbd6cdc5ba7a3c10d676b2d6112ab0e7f\n",
      "  Stored in directory: /Users/gokulsundeep/Library/Caches/pip/wheels/26/dc/ab/e270efb29a2dd807475f9ac7351f086878d184892d14031825\n",
      "Successfully built lxml\n",
      "Installing collected packages: primp, lxml, duckduckgo-search\n",
      "Successfully installed duckduckgo-search-7.2.1 lxml-6.0.0 primp-0.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
